# -*- coding: utf-8 -*-
"""Voting Regressor on CL at rs=150.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MAnWaOB-mVE1x0FTxw6A9e-GF3NlqZ1h
"""

import pandas as pd
import xgboost as xgb
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.model_selection import train_test_split
!pip install scikit-optimize
from skopt import BayesSearchCV
from skopt.space import Real, Integer
from scipy.stats import pearsonr
#import pandas as pd
!pip install catboost
from catboost import CatBoostRegressor, Pool
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.model_selection import train_test_split

# Load the data
url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00242/ENB2012_data.xlsx'
df = pd.read_excel(url)
df.columns = ['Relative_Compactness', 'Surface_Area', 'Wall_Area', 'Roof_Area', 'Overall_Height',
              'Orientation', 'Glazing_Area', 'Glazing_Area_Distribution', 'Heating_Load', 'Cooling_Load']

# Drop Cooling_Load from the dataframe
df.drop(['Heating_Load'], axis=1, inplace=True)

# Split the data
train_data, test_data, train_target, test_target = train_test_split(df.iloc[:, :-1], df.iloc[:, -1],
                                                                    test_size=0.3, random_state=150)

# Create a CatBoost model
catboost_model = CatBoostRegressor(
    iterations=500,  # Adjust as needed
    learning_rate=0.1,  # Adjust as needed
    depth=6,  # Adjust as needed
    loss_function='RMSE',
    random_state=150,
    verbose=200
)

# Fit the model
catboost_model.fit(train_data, train_target)

# Predict on the test set
test_preds = catboost_model.predict(test_data)
train_preds = catboost_model.predict(train_data)

# Calculate metrics
train_rmse = mean_squared_error(train_target, train_preds, squared=False)
test_rmse = mean_squared_error(test_target, test_preds, squared=False)
test_mse = mean_squared_error(test_target, test_preds)
test_mae = mean_absolute_error(test_target, test_preds)
test_r2 = r2_score(test_target, test_preds)
train_r2 = r2_score(train_target, train_preds)

# Print metrics
print(f"Test RMSE: {test_rmse:.2f}")
print(f"Test MSE: {test_mse:.2f}")
print(f"Test MAE: {test_mae:.2f}")
print(f"Test R^2: {test_r2:.2f}")
print(f"Train RMSE: {train_rmse:.2f}")
print(f"Train R^2: {train_r2:.2f}")

# Save the results in Google Colab
result_df = pd.DataFrame({'y_test': test_target, 'y_predict': test_preds})
result_df.to_excel('/content/CatBoost_predictions.xlsx', index=False)


# Provide a download link
from google.colab import files
files.download('/content/CatBoost_predictions.xlsx')

# Create an XGBoost model
xgb_model = xgb.XGBRegressor(
    objective='reg:squarederror',
    booster='gbtree',
    n_jobs=-1,
    random_state=150,
    n_estimators=500,  # Adjust as needed
    learning_rate=0.1,  # Adjust as needed
    max_depth=6,  # Adjust as needed
    subsample=0.8,  # Adjust as needed
    colsample_bytree=0.8  # Adjust as needed
)

# Fit the model
xgb_model.fit(train_data, train_target)

# Predict on the test set
test_preds2 = xgb_model.predict(test_data)
train_preds2 = xgb_model.predict(train_data)

# Calculate metrics
train_rmse = mean_squared_error(train_target, train_preds2, squared=False)
test_rmse = mean_squared_error(test_target, test_preds2, squared=False)
test_mse = mean_squared_error(test_target, test_preds2)
test_mae = mean_absolute_error(test_target, test_preds2)
test_r2 = r2_score(test_target, test_preds2)
train_r2 = r2_score(train_target, train_preds2)

print(f"Train RMSE: {train_rmse:.2f}")
print(f"Test RMSE: {test_rmse:.2f}")
print(f"Test MSE: {test_mse:.2f}")
print(f"Test MAE: {test_mae:.2f}")
print(f"Test R^2: {test_r2:.2f}")
print(f"Train R^2: {train_r2:.2f}")

# Save the results in Google Colab
result_df = pd.DataFrame({'y_test': test_target, 'y_predict': test_preds2})
result_df.to_excel('/content/XGBoost_predictions.xlsx', index=False)


# Provide a download link
from google.colab import files
files.download('/content/XGBoost_predictions.xlsx')

from sklearn.ensemble import VotingRegressor
#catboost_model,xgb_model
# Create Voting Regressor
voting_regressor = VotingRegressor(
    estimators=[
        ('catboost', catboost_model),
        ('xgboost', xgb_model)
    ],
    n_jobs=-1
)

# Fit the Voting Regressor
voting_regressor.fit(train_data, train_target)

# Predict on the test set
test_preds3 = voting_regressor.predict(test_data)
train_preds3 = voting_regressor.predict(train_data)

# Calculate metrics
train_rmse = mean_squared_error(train_target, train_preds3, squared=False)
test_rmse = mean_squared_error(test_target, test_preds3, squared=False)
test_mse = mean_squared_error(test_target, test_preds3)
test_mae = mean_absolute_error(test_target, test_preds3)
test_r2 = r2_score(test_target, test_preds3)
train_r2 = r2_score(train_target, train_preds3)

print(f"Train RMSE: {train_rmse:.2f}")
print(f"Test RMSE: {test_rmse:.2f}")
print(f"Test MSE: {test_mse:.2f}")
print(f"Test MAE: {test_mae:.2f}")
print(f"Test R^2: {test_r2:.2f}")
print(f"Train R^2: {train_r2:.2f}")

# Save the results in Google Colab
result_df = pd.DataFrame({'y_test': test_target, 'y_predict': test_preds3})
result_df.to_excel('/content/Voting_predictions.xlsx', index=False)


# Provide a download link
from google.colab import files
files.download('/content/Voting_predictions.xlsx')



